"""
å¤§è§„æ¨¡æ‹¥å µåœºæ™¯å®éªŒæ¨¡å—
ç”¨äºæµ‹è¯•è®ºæ–‡ä¸­è·¯å¾„è§„åˆ’ç®—æ³•åœ¨ä¸åŒæ‹¥å µåœºæ™¯ä¸‹çš„æ€§èƒ½
"""

import time
import random
import json
from typing import Dict, List, Tuple

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.graph import Graph
from core.route_planner import RoutePlanner

class CongestionExperiment:
    """
    æ‹¥å µåœºæ™¯å®éªŒç±»
    ç”¨äºç”Ÿæˆä¸åŒç¨‹åº¦çš„æ‹¥å µåœºæ™¯å¹¶æµ‹è¯•è·¯å¾„è§„åˆ’ç®—æ³•æ€§èƒ½
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–å®éªŒç±»
        """
        self.planner = RoutePlanner()
        self.graph = self.planner.graph_cache.get_graph()
        self.experiment_results = []
    
    def generate_congestion_scenario(self, congestion_level: str = "moderate") -> Dict:
        """
        ç”Ÿæˆæ‹¥å µåœºæ™¯
        
        Args:
            congestion_level: æ‹¥å µçº§åˆ« ("light", "moderate", "heavy", "extreme")
            
        Returns:
            æ‹¥å µåœºæ™¯é…ç½®å­—å…¸
        """
        # å®šä¹‰æ‹¥å µçº§åˆ«å¯¹åº”çš„å‚æ•°
        congestion_params = {
            "light": {
                "affected_edges_ratio": 0.3,  # 30%çš„è¾¹å—å½±å“
                "congestion_factor_min": 2.0,  # æœ€å°æ‹¥å µå› å­
                "congestion_factor_max": 3.0,  # æœ€å¤§æ‹¥å µå› å­
                "bottleneck_factor": 0.2  # ç“¶é¢ˆè·¯æ®µæ¯”ä¾‹
            },
            "moderate": {
                "affected_edges_ratio": 0.5,
                "congestion_factor_min": 3.0,
                "congestion_factor_max": 4.5,
                "bottleneck_factor": 0.3
            },
            "heavy": {
                "affected_edges_ratio": 0.75,
                "congestion_factor_min": 5.0,
                "congestion_factor_max": 7.0,
                "bottleneck_factor": 0.55
            },
            "extreme": {
                "affected_edges_ratio": 0.9,
                "congestion_factor_min": 6.5,
                "congestion_factor_max": 9.0,
                "bottleneck_factor": 0.65
            }
        }
        
        params = congestion_params.get(congestion_level, congestion_params["moderate"])
        
        # é€‰æ‹©å—å½±å“çš„è¾¹
        all_edges = list(self.graph.edges.keys())
        num_affected = int(len(all_edges) * params["affected_edges_ratio"])
        
        # æ™ºèƒ½é€‰æ‹©å—å½±å“çš„è¾¹ï¼Œä¼˜å…ˆé€‰æ‹©å…³é”®è·¯å¾„
        # 1. è®¡ç®—æ¯æ¡è¾¹çš„é‡è¦æ€§ï¼ˆåŸºäºè¿æ¥çš„èŠ‚ç‚¹åº¦æ•°ï¼‰
        edge_importance = {}
        for edge in all_edges:
            from_node, to_node = edge
            # è¾¹çš„é‡è¦æ€§ = èµ·ç‚¹åº¦æ•° + ç»ˆç‚¹åº¦æ•°
            importance = len(self.graph.adj.get(from_node, [])) + len(self.graph.adj.get(to_node, []))
            edge_importance[edge] = importance
        
        # 2. æŒ‰é‡è¦æ€§æ’åºï¼Œä¼˜å…ˆé€‰æ‹©é‡è¦çš„è¾¹
        sorted_edges = sorted(all_edges, key=lambda x: edge_importance[x], reverse=True)
        
        # 3. é€‰æ‹©å‰num_affectedæ¡é‡è¦çš„è¾¹
        affected_edges = sorted_edges[:num_affected]
        
        # 4. ä¸ºå—å½±å“çš„è¾¹ç”Ÿæˆæ‹¥å µå› å­
        congestion_factors = {}
        num_bottlenecks = int(len(affected_edges) * params["bottleneck_factor"])
        
        for i, edge in enumerate(affected_edges):
            if i < num_bottlenecks:
                # ç“¶é¢ˆè·¯æ®µï¼Œæ‹¥å µå› å­æ›´é«˜
                factor = random.uniform(params["congestion_factor_max"] * 0.9, params["congestion_factor_max"])
            else:
                # æ™®é€šæ‹¥å µè·¯æ®µ
                factor = random.uniform(params["congestion_factor_min"], params["congestion_factor_max"] * 0.6)
            congestion_factors[edge] = factor
        
        return {
            "congestion_level": congestion_level,
            "affected_edges": affected_edges,
            "congestion_factors": congestion_factors,
            "params": params,
            "edge_importance": edge_importance  # è¾¹çš„é‡è¦æ€§ï¼Œç”¨äºè°ƒè¯•
        }
    
    def apply_congestion_scenario(self, scenario: Dict) -> None:
        """
        åº”ç”¨æ‹¥å µåœºæ™¯åˆ°å›¾ä¸­
        
        Args:
            scenario: æ‹¥å µåœºæ™¯é…ç½®å­—å…¸
        """
        for edge, factor in scenario["congestion_factors"].items():
            from_node, to_node = edge
            original_weight = self.graph.get_edge_weight(from_node, to_node)
            if original_weight:
                new_weight = original_weight * factor
                self.graph.update_edge_weight(from_node, to_node, new_weight)
                # æ›´æ–°æ‹¥å µåº¦
                if edge in self.graph.edges:
                    original_congestion = self.graph.edges[edge].get("current_congestion", 0)
                    new_congestion = original_congestion * factor
                    self.graph.edges[edge]["current_congestion"] = new_congestion
        
        # æ›´æ–°ç¼“å­˜ä¸­çš„å›¾
        self.planner.graph_cache._graph = self.graph
        self.planner.graph_cache._last_update = time.time()
    
    def reset_graph(self) -> None:
        """
        é‡ç½®å›¾åˆ°åˆå§‹çŠ¶æ€
        """
        # é‡æ–°åŠ è½½å›¾
        self.graph = Graph.from_database()
        # æ›´æ–°ç¼“å­˜ä¸­çš„å›¾
        self.planner.graph_cache._graph = self.graph
        self.planner.graph_cache._last_update = time.time()
    
    def run_experiment(self, start_node: str, end_node: str, congestion_levels: List[str] = None) -> List[Dict]:
        """
        è¿è¡Œå®éªŒ
        
        Args:
            start_node: èµ·å§‹èŠ‚ç‚¹
            end_node: ç›®æ ‡èŠ‚ç‚¹
            congestion_levels: æ‹¥å µçº§åˆ«åˆ—è¡¨
            
        Returns:
            å®éªŒç»“æœåˆ—è¡¨
        """
        if congestion_levels is None:
            congestion_levels = ["light", "moderate", "heavy", "extreme"]
        
        results = []
        
        # å®šä¹‰ç®—æ³•æ˜ å°„
        algorithms = {
            "SP": "emergency",      # SPç®—æ³•
            "D-KSPP": "normal"       # D-KSPPç®—æ³•
        }
        
        for level in congestion_levels:
            # é‡ç½®å›¾
            self.reset_graph()
            
            # æ¸…é™¤è·¯å¾„ç¼“å­˜
            self.planner.path_cache._cache = {}
            
            # ç”Ÿæˆå¹¶åº”ç”¨æ‹¥å µåœºæ™¯
            scenario = self.generate_congestion_scenario(level)
            self.apply_congestion_scenario(scenario)
            
            # æµ‹è¯•æ¯ç§ç®—æ³•
            for algo_name, vehicle_type in algorithms.items():
                # è¿è¡Œè·¯å¾„è§„åˆ’
                start_time = time.time()
                result = self.planner.plan_route(start_node, end_node, vehicle_type)
                processing_time = time.time() - start_time
                
                # æ”¶é›†å®éªŒæ•°æ®
                experiment_data = {
                    "algorithm": algo_name,
                    "congestion_level": level,
                    "start_node": start_node,
                    "end_node": end_node,
                    "processing_time": processing_time,
                    "path_length": len(result.get("path", [])),
                    "path_weight": result.get("weight", 0),
                    "path_distance": result.get("distance", 0),
                    "path_duration": result.get("duration", 0),
                    "path_congestion": result.get("congestion", 0),
                    "alternative_paths": result.get("alternative_paths", 0),
                    "message": result.get("message", ""),
                    "affected_edges_count": len(scenario["affected_edges"]),
                    "total_edges_count": len(self.graph.edges),
                    "scenario": scenario,
                    "vehicle_type": vehicle_type
                }
                
                results.append(experiment_data)
                print(f"ğŸ“Š å®éªŒå®Œæˆ: {level}æ‹¥å µ - {algo_name}ç®—æ³• - å¤„ç†æ—¶é—´: {processing_time:.3f}s - è·¯å¾„é•¿åº¦: {len(result.get('path', []))}")
        
        self.experiment_results.extend(results)
        return results
    
    def run_batch_experiments(self, test_cases: List[Tuple[str, str]], congestion_levels: List[str] = None) -> List[Dict]:
        """
        è¿è¡Œæ‰¹é‡å®éªŒ
        
        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (start_node, end_node)
            congestion_levels: æ‹¥å µçº§åˆ«åˆ—è¡¨
            
        Returns:
            æ‰€æœ‰å®éªŒç»“æœåˆ—è¡¨
        """
        all_results = []
        
        for start, end in test_cases:
            print(f"ğŸš— å¼€å§‹æµ‹è¯•: {start} -> {end}")
            results = self.run_experiment(start, end, congestion_levels)
            all_results.extend(results)
        
        return all_results
    
    def analyze_results(self, results: List[Dict]) -> Dict:
        """
        åˆ†æå®éªŒç»“æœ
        
        Args:
            results: å®éªŒç»“æœåˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # æŒ‰æ‹¥å µçº§åˆ«å’Œç®—æ³•åˆ†ç»„
        by_congestion_algorithm = {}
        for result in results:
            level = result["congestion_level"]
            algo = result["algorithm"]
            if level not in by_congestion_algorithm:
                by_congestion_algorithm[level] = {}
            if algo not in by_congestion_algorithm[level]:
                by_congestion_algorithm[level][algo] = []
            by_congestion_algorithm[level][algo].append(result)
        
        # è®¡ç®—æ¯ä¸ªæ‹¥å µçº§åˆ«å’Œç®—æ³•çš„ç»Ÿè®¡æ•°æ®
        analysis = {
            "by_congestion_algorithm": {},
            "algorithm_comparison": {},
            "overall_analysis": {},
            "paper_data": {}
        }
        
        # åˆ†ææ¯ä¸ªæ‹¥å µçº§åˆ«
        for level, algo_results in by_congestion_algorithm.items():
            analysis["by_congestion_algorithm"][level] = {}
            
            # åˆ†ææ¯ç§ç®—æ³•
            for algo, results in algo_results.items():
                processing_times = [r["processing_time"] for r in results]
                path_lengths = [r["path_length"] for r in results]
                path_weights = [r["path_weight"] for r in results]
                path_durations = [r["path_duration"] for r in results]
                path_congestions = [r["path_congestion"] for r in results]
                
                # è®¡ç®—æˆåŠŸç‡ï¼šåªè¦è·¯å¾„é•¿åº¦å¤§äº0ï¼Œå°±è®¤ä¸ºæˆåŠŸ
                successful_cases = sum(1 for r in results if r["path_length"] > 0)
                success_rate = successful_cases / len(results) * 100
                
                # è®¡ç®—äº¤é€šæ•ˆç‡è¯„åˆ†ï¼ˆ1/å¹³å‡åˆ°è¾¾æ—¶é—´ï¼‰
                if sum(path_durations) > 0:
                    traffic_efficiency = 1 / (sum(path_durations) / len(path_durations))
                else:
                    traffic_efficiency = 0
                
                analysis["by_congestion_algorithm"][level][algo] = {
                    "average_processing_time": sum(processing_times) / len(processing_times),
                    "average_path_length": sum(path_lengths) / len(path_lengths),
                    "average_path_weight": sum(path_weights) / len(path_weights),
                    "average_path_duration": sum(path_durations) / len(path_durations),
                    "average_path_congestion": sum(path_congestions) / len(path_congestions),
                    "traffic_efficiency": traffic_efficiency,
                    "test_cases": len(results),
                    "successful_cases": successful_cases,
                    "success_rate": success_rate
                }
        
        # ç”Ÿæˆç®—æ³•å¯¹æ¯”åˆ†æ
        congestion_levels = list(by_congestion_algorithm.keys())
        algorithms = list(next(iter(by_congestion_algorithm.values())).keys())
        
        analysis["algorithm_comparison"] = {}
        for level in congestion_levels:
            analysis["algorithm_comparison"][level] = {
                "time_improvement": {},
                "efficiency_improvement": {},
                "weight_reduction": {}
            }
            
            # è®¡ç®—ç®—æ³•ä¹‹é—´çš„å¯¹æ¯”
            if "SP" in by_congestion_algorithm[level] and "D-KSPP" in by_congestion_algorithm[level]:
                sp_stats = analysis["by_congestion_algorithm"][level]["SP"]
                dkspp_stats = analysis["by_congestion_algorithm"][level]["D-KSPP"]
                
                # æ—¶é—´æ”¹è¿›
                if sp_stats["average_path_duration"] > 0:
                    time_improvement = ((sp_stats["average_path_duration"] - dkspp_stats["average_path_duration"]) / 
                                       sp_stats["average_path_duration"]) * 100
                else:
                    time_improvement = 0
                
                # æ•ˆç‡æ”¹è¿›
                if sp_stats["traffic_efficiency"] > 0:
                    efficiency_improvement = ((dkspp_stats["traffic_efficiency"] - sp_stats["traffic_efficiency"]) / 
                                           sp_stats["traffic_efficiency"]) * 100
                else:
                    efficiency_improvement = 0
                
                # æƒé‡å‡å°‘
                if sp_stats["average_path_weight"] > 0:
                    weight_reduction = ((sp_stats["average_path_weight"] - dkspp_stats["average_path_weight"]) / 
                                      sp_stats["average_path_weight"]) * 100
                else:
                    weight_reduction = 0
                
                analysis["algorithm_comparison"][level]["time_improvement"] = time_improvement
                analysis["algorithm_comparison"][level]["efficiency_improvement"] = efficiency_improvement
                analysis["algorithm_comparison"][level]["weight_reduction"] = weight_reduction
                analysis["algorithm_comparison"][level]["sp_stats"] = sp_stats
                analysis["algorithm_comparison"][level]["dkspp_stats"] = dkspp_stats
        
        # ç”Ÿæˆæ€»ä½“åˆ†æ
        analysis["overall_analysis"] = {
            "total_test_cases": len(results),
            "congestion_levels": congestion_levels,
            "algorithms": algorithms,
            "best_algorithm_by_scenario": {}
        }
        
        # ç¡®å®šæ¯ä¸ªåœºæ™¯ä¸‹çš„æœ€ä½³ç®—æ³•
        for level in congestion_levels:
            if "SP" in by_congestion_algorithm[level] and "D-KSPP" in by_congestion_algorithm[level]:
                sp_stats = analysis["by_congestion_algorithm"][level]["SP"]
                dkspp_stats = analysis["by_congestion_algorithm"][level]["D-KSPP"]
                
                # åŸºäºäº¤é€šæ•ˆç‡é€‰æ‹©æœ€ä½³ç®—æ³•
                if dkspp_stats["traffic_efficiency"] > sp_stats["traffic_efficiency"]:
                    best_algorithm = "D-KSPP"
                else:
                    best_algorithm = "SP"
                
                analysis["overall_analysis"]["best_algorithm_by_scenario"][level] = best_algorithm
        
        # ç”Ÿæˆè®ºæ–‡æ”¯æ’‘æ•°æ®
        analysis["paper_data"] = {
            "arrival_time_comparison": {},
            "efficiency_comparison": {},
            "congestion_impact": []
        }
        
        for level in congestion_levels:
            if "SP" in by_congestion_algorithm[level] and "D-KSPP" in by_congestion_algorithm[level]:
                sp_stats = analysis["by_congestion_algorithm"][level]["SP"]
                dkspp_stats = analysis["by_congestion_algorithm"][level]["D-KSPP"]
                comp = analysis["algorithm_comparison"][level]
                
                analysis["paper_data"]["arrival_time_comparison"][level] = {
                    "SP_avg_arrival_time_sec": sp_stats["average_path_duration"],
                    "D_KSPP_avg_arrival_time_sec": dkspp_stats["average_path_duration"],
                    "improvement_percent": comp["time_improvement"]
                }
                
                analysis["paper_data"]["efficiency_comparison"][level] = {
                    "SP_efficiency": sp_stats["traffic_efficiency"],
                    "D_KSPP_efficiency": dkspp_stats["traffic_efficiency"],
                    "improvement_percent": comp["efficiency_improvement"]
                }
                
                # è®¡ç®—æ‹¥å µå½±å“
                analysis["paper_data"]["congestion_impact"].append({
                    "scenario": level,
                    "sp_efficiency": sp_stats["traffic_efficiency"],
                    "dkspp_efficiency": dkspp_stats["traffic_efficiency"],
                    "efficiency_improvement": comp["efficiency_improvement"]
                })
        
        return analysis
    
    def save_results(self, results: List[Dict], filename: str) -> None:
        """
        ä¿å­˜å®éªŒç»“æœåˆ°æ–‡ä»¶
        
        Args:
            results: å®éªŒç»“æœåˆ—è¡¨
            filename: æ–‡ä»¶å
        """
        # è½¬æ¢å…ƒç»„ä¸ºå­—ç¬¦ä¸²ä»¥æ”¯æŒJSONåºåˆ—åŒ–
        def convert_tuples(obj):
            if isinstance(obj, dict):
                return {convert_tuples(k): convert_tuples(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_tuples(item) for item in obj]
            elif isinstance(obj, tuple):
                return str(obj)
            else:
                return obj
        
        # è½¬æ¢ç»“æœ
        converted_results = convert_tuples(results)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(converted_results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    def save_analysis(self, analysis: Dict, filename: str) -> None:
        """
        ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            analysis: åˆ†æç»“æœå­—å…¸
            filename: æ–‡ä»¶å
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")

if __name__ == "__main__":
    """
    è¿è¡Œå¤§è§„æ¨¡æ‹¥å µåœºæ™¯å®éªŒ
    """
    print("ğŸš€ å¼€å§‹å¤§è§„æ¨¡æ‹¥å µåœºæ™¯å®éªŒ...")
    
    # åˆå§‹åŒ–å®éªŒ
    experiment = CongestionExperiment()
    
    # å®šä¹‰æµ‹è¯•ç”¨ä¾‹ï¼ˆè¦†ç›–ä¸åŒè·ç¦»å’Œå¤æ‚åº¦çš„è·¯å¾„ï¼‰
    test_cases = [
        ("A", "Z"),  # é•¿è·ç¦»
        ("B", "Y"),  # é•¿è·ç¦»
        ("C", "X"),  # é•¿è·ç¦»
        ("D", "W"),  # é•¿è·ç¦»
        ("E", "V"),  # é•¿è·ç¦»
        ("F", "K"),  # ä¸­è·ç¦»
        ("G", "N"),  # ä¸­è·ç¦»
        ("H", "O"),  # ä¸­è·ç¦»
        ("I", "L"),  # ä¸­è·ç¦»
        ("J", "M"),  # ä¸­è·ç¦»
    ]
    
    # å®šä¹‰æ‹¥å µçº§åˆ«
    congestion_levels = ["light", "moderate", "heavy", "extreme"]
    
    # è¿è¡Œæ‰¹é‡å®éªŒ
    print(f"ğŸ“‹ è¿è¡Œ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œæ¯ä¸ªç”¨ä¾‹æµ‹è¯• {len(congestion_levels)} ä¸ªæ‹¥å µçº§åˆ«...")
    results = experiment.run_batch_experiments(test_cases, congestion_levels)
    
    # åˆ†æç»“æœ
    print("ğŸ“ˆ åˆ†æå®éªŒç»“æœ...")
    analysis = experiment.analyze_results(results)
    
    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    results_file = f"experiments/results/congestion_experiment_final_{timestamp}.json"
    analysis_file = f"experiments/results/congestion_analysis_final_{timestamp}.json"
    
    experiment.save_results(results, results_file)
    experiment.save_analysis(analysis, analysis_file)
    
    # æ‰“å°è¯¦ç»†åˆ†æç»“æœ
    print("\n" + "=" * 100)
    print("ğŸ“Š å¤§è§„æ¨¡æ‹¥å µåœºæ™¯å®éªŒåˆ†ææŠ¥å‘Š")
    print("=" * 100)
    
    # æ‰“å°æ€»ä½“åˆ†æ
    print("\nğŸ“ˆ æ€»ä½“åˆ†æ:")
    print(f"  â€¢ æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {analysis['overall_analysis']['total_test_cases']}")
    print(f"  â€¢ æµ‹è¯•æ‹¥å µçº§åˆ«: {', '.join(analysis['overall_analysis']['congestion_levels'])}")
    print(f"  â€¢ æµ‹è¯•ç®—æ³•: {', '.join(analysis['overall_analysis']['algorithms'])}")
    print(f"  â€¢ æ¯ä¸ªåœºæ™¯æœ€ä½³ç®—æ³•: {analysis['overall_analysis']['best_algorithm_by_scenario']}")
    
    # æ‰“å°ç®—æ³•å¯¹æ¯”åˆ†æ
    print("\n" + "-" * 80)
    print("ğŸ† ç®—æ³•å¯¹æ¯”åˆ†æ:")
    print("-" * 80)
    
    for level in analysis['algorithm_comparison']:
        comp = analysis['algorithm_comparison'][level]
        print(f"\nğŸ“‹ æ‹¥å µåœºæ™¯: {level.upper()}")
        print(f"  â€¢ æ—¶é—´æ”¹è¿›: {comp['time_improvement']:.2f}%")
        print(f"  â€¢ æ•ˆç‡æ”¹è¿›: {comp['efficiency_improvement']:.2f}%")
        print(f"  â€¢ æƒé‡å‡å°‘: {comp['weight_reduction']:.2f}%")
        
        # æ‰“å°æ¯ç§ç®—æ³•çš„è¯¦ç»†æ•°æ®
        print(f"  \n  SPç®—æ³•:")
        print(f"    - å¹³å‡å¤„ç†æ—¶é—´: {comp['sp_stats']['average_processing_time']:.3f}s")
        print(f"    - å¹³å‡è·¯å¾„é•¿åº¦: {comp['sp_stats']['average_path_length']:.1f} èŠ‚ç‚¹")
        print(f"    - å¹³å‡è·¯å¾„æ—¶é—´: {comp['sp_stats']['average_path_duration']:.2f}s")
        print(f"    - äº¤é€šæ•ˆç‡: {comp['sp_stats']['traffic_efficiency']:.4f}")
        print(f"    - æˆåŠŸç‡: {comp['sp_stats']['success_rate']:.2f}%")
        
        print(f"  \n  D-KSPPç®—æ³•:")
        print(f"    - å¹³å‡å¤„ç†æ—¶é—´: {comp['dkspp_stats']['average_processing_time']:.3f}s")
        print(f"    - å¹³å‡è·¯å¾„é•¿åº¦: {comp['dkspp_stats']['average_path_length']:.1f} èŠ‚ç‚¹")
        print(f"    - å¹³å‡è·¯å¾„æ—¶é—´: {comp['dkspp_stats']['average_path_duration']:.2f}s")
        print(f"    - äº¤é€šæ•ˆç‡: {comp['dkspp_stats']['traffic_efficiency']:.4f}")
        print(f"    - æˆåŠŸç‡: {comp['dkspp_stats']['success_rate']:.2f}%")
    
    # æ‰“å°è®ºæ–‡æ”¯æ’‘æ•°æ®
    print("\n" + "-" * 80)
    print("ğŸ“š è®ºæ–‡æ”¯æ’‘æ•°æ®:")
    print("-" * 80)
    
    print("\n1. åˆ°è¾¾æ—¶é—´å¯¹æ¯”:")
    for level, data in analysis['paper_data']['arrival_time_comparison'].items():
        print(f"  â€¢ {level}: SP={data['SP_avg_arrival_time_sec']:.2f}s, D-KSPP={data['D_KSPP_avg_arrival_time_sec']:.2f}s, æ”¹è¿›{data['improvement_percent']:.2f}%")
    
    print("\n2. æ•ˆç‡å¯¹æ¯”:")
    for level, data in analysis['paper_data']['efficiency_comparison'].items():
        print(f"  â€¢ {level}: SP={data['SP_efficiency']:.4f}, D-KSPP={data['D_KSPP_efficiency']:.4f}, æ”¹è¿›{data['improvement_percent']:.2f}%")
    
    print("\n3. æ‹¥å µå½±å“åˆ†æ:")
    for impact in analysis['paper_data']['congestion_impact']:
        print(f"  â€¢ åœºæ™¯: {impact['scenario']}, æ•ˆç‡æ”¹è¿›: {impact['efficiency_improvement']:.2f}%")
    
    # æ‰“å°ä¿å­˜ä¿¡æ¯
    print("\n" + "=" * 100)
    print("ğŸ’¾ å®éªŒç»“æœä¿å­˜:")
    print(f"  â€¢ åŸå§‹å®éªŒæ•°æ®: {results_file}")
    print(f"  â€¢ åˆ†æç»“æœæ•°æ®: {analysis_file}")
    print("=" * 100)
    
    print("\nğŸ‰ å®éªŒå®Œæˆï¼æˆåŠŸç”Ÿæˆè¯¦ç»†çš„ç®—æ³•å¯¹æ¯”åˆ†ææŠ¥å‘Šã€‚")
