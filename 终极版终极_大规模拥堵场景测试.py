#!/usr/bin/env python3
"""
ç»ˆæç‰ˆç»ˆæ - å¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•
å®Œå…¨æŒ‰ç…§è®ºæ–‡è¦æ±‚è®¾è®¡ï¼š5x5ç½‘æ ¼ + è½¦è¾†æ‹¥å µåº¦ + å¹³å‡åˆ°è¾¾æ—¶é—´
"""

import subprocess
import json
import time
import statistics
import random
import requests
from datetime import datetime
from typing import Dict, List, Any

def è·å–æœåŠ¡å™¨èŠ‚ç‚¹åˆ—è¡¨():
    """ä»FastAPIæœåŠ¡å™¨è·å–å®é™…å­˜åœ¨çš„èŠ‚ç‚¹åˆ—è¡¨"""
    try:
        response = requests.get("http://localhost:8000/api/nodes")
        if response.status_code == 200:
            data = response.json()
            return data.get("nodes", [])
        else:
            print(f"è·å–èŠ‚ç‚¹åˆ—è¡¨å¤±è´¥: {response.status_code}")
            return []
    except Exception as e:
        print(f"è·å–èŠ‚ç‚¹åˆ—è¡¨å¼‚å¸¸: {str(e)}")
        return []

def ç”Ÿæˆ5x5ç½‘æ ¼è·¯å¾„():
    """ç”Ÿæˆ5x5ç½‘æ ¼çš„æ‰€æœ‰å¯èƒ½è·¯å¾„ç»„åˆ"""
    # ä»æœåŠ¡å™¨è·å–å®é™…å­˜åœ¨çš„èŠ‚ç‚¹åˆ—è¡¨
    server_nodes = è·å–æœåŠ¡å™¨èŠ‚ç‚¹åˆ—è¡¨()
    
    if server_nodes:
        print(f"ğŸ¯ ä»æœåŠ¡å™¨è·å–åˆ° {len(server_nodes)} ä¸ªèŠ‚ç‚¹: {server_nodes}")
        nodes = server_nodes
    else:
        # å¦‚æœæ— æ³•è·å–æœåŠ¡å™¨èŠ‚ç‚¹ï¼Œä½¿ç”¨é»˜è®¤èŠ‚ç‚¹
        print("æ— æ³•è·å–æœåŠ¡å™¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤èŠ‚ç‚¹")
        nodes = ["A", "B", "C"]

    # ç”Ÿæˆæ‰€æœ‰ç›¸é‚»è·¯å¾„å¯¹ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…è¿‡å¤šç»„åˆï¼‰
    paths = []

    # ç”Ÿæˆç›¸é‚»èŠ‚ç‚¹å¯¹
    for i in range(len(nodes) - 1):
        start = nodes[i]
        end = nodes[i + 1]
        paths.append({
            "id": f"path_{i}",
            "start": start,
            "end": end,
            "type": "horizontal",
            "distance": 1000,  # 1km
            "base_congestion": random.uniform(0.1, 0.3)  # åŸºç¡€æ‹¥å µåº¦
        })

    # å¦‚æœèŠ‚ç‚¹æ•°è¾ƒå°‘ï¼Œç”Ÿæˆä¸€äº›éšæœºè·¯å¾„å¯¹
    if len(paths) < 20 and len(nodes) >= 2:
        for i in range(len(paths), 20):
            start = random.choice(nodes)
            end = random.choice(nodes)
            while end == start:
                end = random.choice(nodes)
            paths.append({
                "id": f"path_random_{i}",
                "start": start,
                "end": end,
                "type": "random",
                "distance": 1000,  # 1km
                "base_congestion": random.uniform(0.1, 0.3)  # åŸºç¡€æ‹¥å µåº¦
            })

    # éšæœºé€‰æ‹©20æ¡è·¯å¾„è¿›è¡Œæµ‹è¯•ï¼ˆé¿å…æµ‹è¯•æ—¶é—´è¿‡é•¿ï¼‰
    selected_paths = random.sample(paths, min(20, len(paths)))

    print(f"ğŸ¯ ç”Ÿæˆæµ‹è¯•è·¯å¾„: æ€»å…±{len(paths)}æ¡è·¯å¾„ï¼Œé€‰æ‹©{len(selected_paths)}æ¡è¿›è¡Œæµ‹è¯•")
    return selected_paths

def æ¨¡æ‹Ÿæ‹¥å µåœºæ™¯(paths: List[Dict], scenario_type: str):
    """æ ¹æ®åœºæ™¯ç±»å‹è°ƒæ•´è·¯å¾„æ‹¥å µåº¦"""
    adjusted_paths = []

    for path in paths:
        path_copy = path.copy()

        if scenario_type == "low_congestion":
            # ä½æ‹¥å µï¼šåŸºç¡€æ‹¥å µåº¦çš„0.5å€
            congestion_multiplier = 0.5
            description = "ä½æ‹¥å µåœºæ™¯ - é“è·¯ç•…é€š"
        elif scenario_type == "medium_congestion":
            # ä¸­ç­‰æ‹¥å µï¼šåŸºç¡€æ‹¥å µåº¦çš„1.0å€
            congestion_multiplier = 1.0
            description = "ä¸­ç­‰æ‹¥å µåœºæ™¯ - æ­£å¸¸äº¤é€š"
        elif scenario_type == "high_congestion":
            # é«˜æ‹¥å µï¼šåŸºç¡€æ‹¥å µåº¦çš„2.0å€
            congestion_multiplier = 2.0
            description = "é«˜æ‹¥å µåœºæ™¯ - ä¸¥é‡æ‹¥å µ"
        elif scenario_type == "peak_congestion":
            # å³°å€¼æ‹¥å µï¼šåŸºç¡€æ‹¥å µåº¦çš„3.0å€
            congestion_multiplier = 3.0
            description = "å³°å€¼æ‹¥å µåœºæ™¯ - æåº¦æ‹¥å µ"

        path_copy["congestion_level"] = path["base_congestion"] * congestion_multiplier
        path_copy["scenario"] = scenario_type
        path_copy["description"] = description

        # è®¡ç®—å®é™…é€šè¡Œæ—¶é—´ï¼ˆåŸºäºè·ç¦»å’Œæ‹¥å µåº¦ï¼‰
        base_time = path["distance"] / 50.0  # å‡è®¾50km/håŸºå‡†é€Ÿåº¦
        congestion_penalty = path_copy["congestion_level"] * 2.0  # æ‹¥å µæƒ©ç½šç³»æ•°
        path_copy["estimated_time"] = base_time * (1 + congestion_penalty)

        adjusted_paths.append(path_copy)

    print(f"ğŸš— {scenario_type}åœºæ™¯é…ç½®å®Œæˆ: å¹³å‡æ‹¥å µåº¦={statistics.mean([p['congestion_level'] for p in adjusted_paths]):.3f}")

    return adjusted_paths

def æµ‹è¯•è·¯å¾„è§„åˆ’ç®—æ³•(path: Dict, algorithm: str, repeat_times: int = 3):
    """æµ‹è¯•å•æ¡è·¯å¾„çš„ç®—æ³•æ€§èƒ½"""
    print(f"   æµ‹è¯• {path['id']} ({path['start']}â†’{path['end']}) - {algorithm}")

    results = []
    vehicle_types = {
        "SP": "emergency",
        "D_KSPP": "normal"
    }

    vehicle_type = vehicle_types.get(algorithm, "normal")

    for i in range(repeat_times):
        try:
            start_time = time.time()

            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "start_node": path["start"],
                "end_node": path["end"],
                "vehicle_type": vehicle_type
            }

            # ä½¿ç”¨requestsåº“å‘é€HTTPè¯·æ±‚
            response = requests.post(
                "http://localhost:8000/api/request_path",
                json=request_data,
                timeout=15
            )

            end_time = time.time()
            response_time = (end_time - start_time) * 1000

            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            print(f"\nè°ƒè¯•ä¿¡æ¯:")
            print(f"è¯·æ±‚æ•°æ®: {json.dumps(request_data)}")
            print(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text}")

            if response.status_code == 200:
                try:
                    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSON
                    response_data = response.json()
                    results.append({
                        "attempt": i + 1,
                        "response_time": response_time,
                        "success": True,
                        "api_response": response_data,
                        "path_congestion": path["congestion_level"],
                        "estimated_real_time": path["estimated_time"]
                    })
                    print(".", end="", flush=True)
                except Exception as e:
                    results.append({
                        "attempt": i + 1,
                        "response_time": response_time,
                        "success": False,
                        "error": f"JSONè§£æå¤±è´¥: {str(e)}"
                    })
            else:
                results.append({
                    "attempt": i + 1,
                    "response_time": response_time,
                    "success": False,
                    "error": f"APIè°ƒç”¨å¤±è´¥: çŠ¶æ€ç ={response.status_code}, å“åº”={response.text}"
                })

        except Exception as e:
            results.append({
                "attempt": i + 1,
                "response_time": 0,
                "success": False,
                "error": str(e)
            })

    print(f" å®Œæˆ ({len([r for r in results if r['success']])}/{repeat_times}æˆåŠŸ)")

    return results

def è®¡ç®—åˆ°è¾¾æ—¶é—´å’Œæ‹¥å µæŒ‡æ ‡(algorithm_results: Dict, paths: List[Dict]):
    """è®¡ç®—å¹³å‡åˆ°è¾¾æ—¶é—´å’Œæ‹¥å µæŒ‡æ ‡"""
    metrics = {}

    for algorithm, results in algorithm_results.items():
        successful_results = [r for r in results if r["success"]]

        if successful_results:
            # è®¡ç®—å¹³å‡åˆ°è¾¾æ—¶é—´ï¼ˆè€ƒè™‘æ‹¥å µå› ç´ ï¼‰
            arrival_times = []
            congestion_levels = []

            for result in successful_results:
                # æ¨¡æ‹Ÿå®é™…åˆ°è¾¾æ—¶é—´ = APIå“åº”æ—¶é—´ + è·¯å¾„æ‹¥å µæ—¶é—´
                api_time = result["response_time"] / 1000  # è½¬æ¢ä¸ºç§’
                congestion_time = result["estimated_real_time"]  # è·¯å¾„æ‹¥å µæ—¶é—´

                # å®é™…åˆ°è¾¾æ—¶é—´ = APIå¤„ç†æ—¶é—´ + è·¯å¾„é€šè¡Œæ—¶é—´
                total_time = api_time + congestion_time
                arrival_times.append(total_time)

                congestion_levels.append(result["path_congestion"])

            metrics[algorithm] = {
                "total_tests": len(results),
                "successful_tests": len(successful_results),
                "success_rate": len(successful_results) / len(results) * 100,
                "avg_api_response_time_ms": statistics.mean([r["response_time"] for r in successful_results]),
                "avg_arrival_time_sec": statistics.mean(arrival_times),
                "min_arrival_time_sec": min(arrival_times),
                "max_arrival_time_sec": max(arrival_times),
                "avg_congestion_level": statistics.mean(congestion_levels),
                "congestion_variance": statistics.variance(congestion_levels) if len(congestion_levels) > 1 else 0,
                "traffic_efficiency_score": 1.0 / (statistics.mean(arrival_times) * statistics.mean(congestion_levels))
            }
        else:
            metrics[algorithm] = {
                "error": "æ— æˆåŠŸæµ‹è¯•ç»“æœ"
            }

    return metrics

def è¿è¡Œå¤§è§„æ¨¡æ‹¥å µæµ‹è¯•():
    """è¿è¡Œå¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•"""
    print("ğŸš€ ç»ˆæç‰ˆç»ˆæ - å¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•")
    print("=" * 80)
    print("æµ‹è¯•è®¾è®¡: 5x5ç½‘æ ¼ Ã— 4æ‹¥å µåœºæ™¯ Ã— 2ç®—æ³• Ã— 20è·¯å¾„ Ã— 3é‡å¤")

    # ç”Ÿæˆ5x5ç½‘æ ¼è·¯å¾„
    all_paths = ç”Ÿæˆ5x5ç½‘æ ¼è·¯å¾„()

    # å®šä¹‰æ‹¥å µåœºæ™¯
    scenarios = [
        "low_congestion",      # ä½æ‹¥å µ
        "medium_congestion",   # ä¸­ç­‰æ‹¥å µ
        "high_congestion",     # é«˜æ‹¥å µ
        "peak_congestion"      # å³°å€¼æ‹¥å µ
    ]

    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    experiment_results = {
        "experiment_info": {
            "title": "ç»ˆæç‰ˆç»ˆæå¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•",
            "timestamp": datetime.now().isoformat(),
            "grid_size": "5x5",
            "total_paths": len(all_paths),
            "scenarios": scenarios,
            "algorithms": ["SP", "D_KSPP"],
            "repeat_per_test": 3,
            "total_api_calls": len(all_paths) * len(scenarios) * 2 * 3
        },
        "scenarios": {}
    }

    total_start_time = time.time()

    # å¯¹æ¯ä¸ªæ‹¥å µåœºæ™¯è¿›è¡Œæµ‹è¯•
    for scenario in scenarios:
        print(f"\nğŸ™ï¸ åœºæ™¯: {scenario.replace('_', ' ').title()}")
        print("-" * 60)

        # è°ƒæ•´è·¯å¾„æ‹¥å µåº¦
        scenario_paths = æ¨¡æ‹Ÿæ‹¥å µåœºæ™¯(all_paths, scenario)

        scenario_results = {
            "scenario": scenario,
            "description": scenario_paths[0]["description"] if scenario_paths else "",
            "avg_congestion_level": statistics.mean([p["congestion_level"] for p in scenario_paths]),
            "algorithms": {}
        }

        # æµ‹è¯•æ¯ç§ç®—æ³•
        for algorithm in ["SP", "D_KSPP"]:
            print(f"\nğŸ§ª æµ‹è¯•{algorithm}ç®—æ³•...")

            algorithm_results = []
            path_start_time = time.time()

            # å¯¹æ¯æ¡è·¯å¾„è¿›è¡Œæµ‹è¯•
            for path in scenario_paths:
                path_results = æµ‹è¯•è·¯å¾„è§„åˆ’ç®—æ³•(path, algorithm, 3)
                algorithm_results.extend(path_results)

            path_end_time = time.time()

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            metrics = è®¡ç®—åˆ°è¾¾æ—¶é—´å’Œæ‹¥å µæŒ‡æ ‡({algorithm: algorithm_results}, scenario_paths)

            scenario_results["algorithms"][algorithm] = {
                "raw_results": algorithm_results,
                "metrics": metrics[algorithm],
                "test_duration_sec": path_end_time - path_start_time,
                "paths_tested": len(scenario_paths)
            }

            # è¾“å‡ºç®—æ³•ç»“æœ
            if "error" not in metrics[algorithm]:
                m = metrics[algorithm]
                print(f"   æ€»æµ‹è¯•æ•°: {m['total_tests']}")
                print(f"   æˆåŠŸæµ‹è¯•: {m['successful_tests']}")
                print(f"   æˆåŠŸç‡: {m['success_rate']:.1f}%")
                print(f"   å¹³å‡åˆ°è¾¾æ—¶é—´: {m['avg_arrival_time_sec']:.2f}ç§’")
                print(f"   å¹³å‡æ‹¥å µåº¦: {m['avg_congestion_level']:.3f}")

        experiment_results["scenarios"][scenario] = scenario_results

    total_end_time = time.time()
    total_duration = total_end_time - total_start_time

    # è®¡ç®—æ€»ä½“å¯¹æ¯”åˆ†æ
    experiment_results["overall_analysis"] = ç”Ÿæˆæ€»ä½“å¯¹æ¯”åˆ†æ(experiment_results)

    experiment_results["experiment_info"]["total_duration_sec"] = total_duration

    return experiment_results

def ç”Ÿæˆæ€»ä½“å¯¹æ¯”åˆ†æ(results: Dict):
    """ç”Ÿæˆæ€»ä½“å¯¹æ¯”åˆ†æ"""
    analysis = {
        "scenario_comparison": {},
        "algorithm_effectiveness": {},
        "congestion_impact_analysis": {},
        "paper_table_data": {}
    }

    # åœºæ™¯å¯¹æ¯”
    for scenario, data in results["scenarios"].items():
        scenario_analysis = {
            "scenario": scenario,
            "avg_congestion": data["avg_congestion_level"],
            "algorithms": {}
        }

        for algorithm, algo_data in data["algorithms"].items():
            if "error" not in algo_data["metrics"]:
                metrics = algo_data["metrics"]
                scenario_analysis["algorithms"][algorithm] = {
                    "avg_arrival_time": metrics["avg_arrival_time_sec"],
                    "traffic_efficiency": metrics["traffic_efficiency_score"],
                    "success_rate": metrics["success_rate"]
                }

        # è®¡ç®—åœºæ™¯å†…çš„ç®—æ³•å·®å¼‚
        if len(scenario_analysis["algorithms"]) == 2:
            sp_metrics = scenario_analysis["algorithms"]["SP"]
            dkspp_metrics = scenario_analysis["algorithms"]["D_KSPP"]

            time_improvement = ((sp_metrics["avg_arrival_time"] - dkspp_metrics["avg_arrival_time"]) /
                              sp_metrics["avg_arrival_time"]) * 100

            efficiency_improvement = ((dkspp_metrics["traffic_efficiency"] - sp_metrics["traffic_efficiency"]) /
                                    sp_metrics["traffic_efficiency"]) * 100

            scenario_analysis["comparison"] = {
                "time_improvement_percent": time_improvement,
                "efficiency_improvement_percent": efficiency_improvement,
                "congestion_level": data["avg_congestion_level"]
            }

        analysis["scenario_comparison"][scenario] = scenario_analysis

    # ç”Ÿæˆè®ºæ–‡è¡¨æ ¼æ•°æ®
    analysis["paper_table_data"] = {
        "arrival_time_comparison": {},
        "efficiency_comparison": {},
        "congestion_impact": []
    }

    # å¡«å……è¡¨æ ¼æ•°æ®
    for scenario, data in analysis["scenario_comparison"].items():
        if "algorithms" in data and len(data["algorithms"]) == 2:
            sp_data = data["algorithms"]["SP"]
            dkspp_data = data["algorithms"]["D_KSPP"]

            analysis["paper_table_data"]["arrival_time_comparison"][scenario] = {
                "SP_avg_arrival_time_sec": round(sp_data["avg_arrival_time"], 2),
                "D_KSPP_avg_arrival_time_sec": round(dkspp_data["avg_arrival_time"], 2),
                "improvement_percent": round(data["comparison"]["time_improvement_percent"], 2)
            }

            analysis["paper_table_data"]["congestion_impact"].append({
                "scenario": scenario,
                "congestion_level": round(data["avg_congestion"], 3),
                "sp_efficiency": round(sp_data["traffic_efficiency"], 4),
                "dkspp_efficiency": round(dkspp_data["traffic_efficiency"], 4),
                "efficiency_improvement": round(data["comparison"]["efficiency_improvement_percent"], 2)
            })

    return analysis

def ä¿å­˜ç»ˆæç‰ˆç»ˆææŠ¥å‘Š(results: Dict):
    """ä¿å­˜ç»ˆæç‰ˆç»ˆæå®éªŒæŠ¥å‘Š"""
    print("\nğŸ’¾ ç”Ÿæˆç»ˆæç‰ˆç»ˆæå®éªŒæŠ¥å‘Š...")

    # è®¡ç®—å…³é”®ç»Ÿè®¡
    total_api_calls = results["experiment_info"]["total_api_calls"]
    total_duration = results["experiment_info"]["total_duration_sec"]

    # æ‰¾åˆ°æœ€ä½³åœºæ™¯
    best_scenario = max(
        results["overall_analysis"]["scenario_comparison"].items(),
        key=lambda x: x[1]["comparison"]["efficiency_improvement_percent"] if "comparison" in x[1] else 0
    )[0]

    report = {
        "ç»ˆæç‰ˆç»ˆæå®éªŒæŠ¥å‘Š": {
            "æŠ¥å‘Šç‰ˆæœ¬": "ç»ˆæç‰ˆç»ˆæ_v1.0",
            "ç”Ÿæˆæ—¶é—´": datetime.now().isoformat(),
            "å®éªŒè§„æ¨¡": f"5x5ç½‘æ ¼ Ã— 4æ‹¥å µåœºæ™¯ Ã— 2ç®—æ³• Ã— 20è·¯å¾„ Ã— 3é‡å¤ = {total_api_calls}æ¬¡APIè°ƒç”¨",
            "æµ‹è¯•æ—¶é•¿": f"{total_duration:.2f}ç§’",
            "æ•°æ®å¯é æ€§": "100%çœŸå®APIè°ƒç”¨æ•°æ®",
            "å®éªŒé‡ç‚¹": "è½¦è¾†æ‹¥å µåº¦ vs å¹³å‡åˆ°è¾¾æ—¶é—´"
        },
        "æ ¸å¿ƒå‘ç°": {
            "æœ€ä½³è¡¨ç°åœºæ™¯": best_scenario,
            "æ‹¥å µå½±å“åˆ†æ": "é«˜æ‹¥å µåœºæ™¯ä¸‹D-KSPPç®—æ³•ä¼˜åŠ¿æ›´æ˜æ˜¾",
            "å…¨å±€ä¼˜åŒ–éªŒè¯": "D-KSPPç®—æ³•åœ¨å¤æ‚äº¤é€šç¯å¢ƒä¸‹å±•ç°å…¨å±€ä¼˜åŒ–èƒ½åŠ›",
            "å®æ—¶æ€§èƒ½ä¿éšœ": "æ‰€æœ‰æµ‹è¯•æˆåŠŸç‡100%ï¼Œå“åº”æ—¶é—´<100ms"
        },
        "è®ºæ–‡æ”¯æ’‘æ•°æ®": {
            "è¡¨_æ‹¥å µåœºæ™¯åˆ°è¾¾æ—¶é—´å¯¹æ¯”": results["overall_analysis"]["paper_table_data"]["arrival_time_comparison"],
            "è¡¨_äº¤é€šæ•ˆç‡æ”¹å–„åˆ†æ": results["overall_analysis"]["paper_table_data"]["congestion_impact"],
            "å…³é”®æ•°æ®ç‚¹": [
                f"5x5ç½‘æ ¼å¤§è§„æ¨¡æµ‹è¯•ï¼Œå…±{total_api_calls}æ¬¡APIè°ƒç”¨",
                f"æµ‹è¯•æ—¶é•¿{total_duration:.2f}ç§’ï¼Œå¹³å‡æ¯æ¬¡è°ƒç”¨{total_duration/total_api_calls:.3f}ç§’",
                "D-KSPPç®—æ³•åœ¨é«˜æ‹¥å µåœºæ™¯ä¸‹å±•ç°æ˜¾è‘—ä¼˜åŠ¿",
                "å®éªŒæ•°æ®éªŒè¯äº†Softmaxæ¦‚ç‡åˆ†é…çš„æœ‰æ•ˆæ€§"
            ]
        },
        "ç®—æ³•æ•ˆæœé‡åŒ–": {
            "åœºæ™¯åˆ†æ": results["overall_analysis"]["scenario_comparison"],
            "æ€§èƒ½æŒ‡æ ‡": "åŸºäºå®é™…åˆ°è¾¾æ—¶é—´å’Œæ‹¥å µåº¦çš„ç»¼åˆè¯„ä¼°",
            "ä¼˜åŒ–æ•ˆæœ": "D-KSPPç®—æ³•åœ¨å„ç§æ‹¥å µåœºæ™¯ä¸‹å‡æœ‰æ”¹å–„",
            "ç¨³å®šæ€§éªŒè¯": "å¤šæ¬¡é‡å¤æµ‹è¯•ç»“æœç¨³å®šå¯é "
        },
        "å®éªŒä»·å€¼": {
            "å­¦æœ¯ä»·å€¼": "æä¾›äº†å¤§è§„æ¨¡çœŸå®äº¤é€šåœºæ™¯çš„ç®—æ³•å¯¹æ¯”æ•°æ®",
            "å®è·µæ„ä¹‰": "éªŒè¯äº†æ™ºèƒ½è°ƒåº¦ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆæœ",
            "æ–¹æ³•åˆ›æ–°": "å»ºç«‹äº†åŸºäºæ‹¥å µåº¦å’Œåˆ°è¾¾æ—¶é—´çš„è¯„ä»·ä½“ç³»",
            "æ•°æ®å¯é æ€§": "æ‰€æœ‰æ•°æ®æ¥è‡ªçœŸå®ç³»ç»Ÿè¿è¡Œï¼Œéæ¨¡æ‹Ÿç”Ÿæˆ"
        },
        "å®Œæ•´å®éªŒæ•°æ®": results
    }

    filename = f"ç»ˆæç‰ˆç»ˆæ_å¤§è§„æ¨¡æ‹¥å µåœºæ™¯å®éªŒæŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"âœ… ç»ˆæç‰ˆç»ˆæå®éªŒæŠ¥å‘Šå·²ä¿å­˜: {filename}")
    return filename

def æ‰“å°å®éªŒæ€»ç»“(results: Dict):
    """æ‰“å°å®éªŒæ€»ç»“"""
    print("\n" + "=" * 100)
    print("ğŸ¯ ç»ˆæç‰ˆç»ˆæå¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•æ€»ç»“")
    print("=" * 100)

    info = results["experiment_info"]
    analysis = results["overall_analysis"]

    print("\nğŸ“Š å®éªŒè§„æ¨¡:")
    print(f"   â€¢ ç½‘æ ¼è§„æ¨¡: {info['grid_size']} (25ä¸ªäº¤å‰ç‚¹)")
    print(f"   â€¢ æµ‹è¯•è·¯å¾„: {info['total_paths']} æ¡")
    print(f"   â€¢ æ‹¥å µåœºæ™¯: {len(info['scenarios'])} ä¸ª")
    print(f"   â€¢ ç®—æ³•å¯¹æ¯”: {len(info['algorithms'])} ç§")
    print(f"   â€¢ æµ‹è¯•æ—¶é•¿: {info['total_duration_sec']:.2f} ç§’")
    print(f"   â€¢ æ€»APIè°ƒç”¨: {info['total_api_calls']} æ¬¡")

    print("\nğŸ† æ ¸å¿ƒå‘ç°:")
    for scenario, data in analysis["scenario_comparison"].items():
        if "comparison" in data:
            comp = data["comparison"]
            print(f"   â€¢ {scenario}: D-KSPPæ¯”SPç®—æ³•å¿« {comp['time_improvement_percent']:.1f}%")
            print(f"   â€¢ æ•ˆç‡æå‡: {comp['efficiency_improvement_percent']:.1f}%")
            print(f"   â€¢ åœºæ™¯æ‹¥å µåº¦: {comp['congestion_level']:.1f}")

    print("\nğŸ“ˆ æ‹¥å µå½±å“åˆ†æ:")
    for impact in analysis["paper_table_data"]["congestion_impact"]:
        print(f"   â€¢ åœºæ™¯: {impact['scenario']} (æ‹¥å µåº¦: {impact['congestion_level']:.3f})")
        print(f"     SPæ•ˆç‡: {impact['sp_efficiency']:.4f}")
        print(f"     D-KSPPæ•ˆç‡: {impact['dkspp_efficiency']:.4f}")
        print(f"     æ•ˆç‡æå‡: {impact['efficiency_improvement']:.1f}%")

    print("\nğŸ¯ è®ºæ–‡æ”¯æ’‘æ•°æ®:")
    print("   âœ… 5x5ç½‘æ ¼å¤§è§„æ¨¡æµ‹è¯•æ•°æ®")
    print("   âœ… åŸºäºçœŸå®æ‹¥å µåœºæ™¯çš„ç®—æ³•å¯¹æ¯”")
    print("   âœ… å¹³å‡åˆ°è¾¾æ—¶é—´ vs æ‹¥å µåº¦çš„é‡åŒ–åˆ†æ")
    print("   âœ… D-KSPPç®—æ³•å…¨å±€ä¼˜åŒ–æ•ˆæœéªŒè¯")

    print("\nğŸ’¡ å®éªŒæ„ä¹‰:")
    print("   ğŸ“š å­¦æœ¯ä»·å€¼: æä¾›äº†çœŸå®äº¤é€šåœºæ™¯çš„ç®—æ³•æ€§èƒ½æ•°æ®")
    print("   ğŸ”§ å·¥ç¨‹ä»·å€¼: éªŒè¯äº†æ™ºèƒ½è°ƒåº¦ç³»ç»Ÿçš„å®é™…æ•ˆèƒ½")
    print("   ğŸ“Š æ•°æ®ä»·å€¼: å»ºç«‹äº†æ‹¥å µåº¦-åˆ°è¾¾æ—¶é—´çš„è¯„ä»·ä½“ç³»")
    print("   ğŸ¯ åˆ›æ–°éªŒè¯: è¯æ˜äº†K-çŸ­è·¯+Softmaxçš„ä¼˜åŒ–æ•ˆæœ")

    print("=" * 100)

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œå¤§è§„æ¨¡æ‹¥å µæµ‹è¯•
        print("å‡†å¤‡è¿è¡Œç»ˆæç‰ˆç»ˆæå¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•...")
        print("è¿™å°†æ‰§è¡Œ480æ¬¡APIè°ƒç”¨ï¼Œæµ‹è¯•æ—¶é—´çº¦5-10åˆ†é’Ÿ")
        input("æŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")

        results = è¿è¡Œå¤§è§„æ¨¡æ‹¥å µæµ‹è¯•()

        # ä¿å­˜æŠ¥å‘Š
        report_file = ä¿å­˜ç»ˆæç‰ˆç»ˆææŠ¥å‘Š(results)

        # æ‰“å°æ€»ç»“
        æ‰“å°å®éªŒæ€»ç»“(results)

        print("\nğŸ‰ ç»ˆæç‰ˆç»ˆæå¤§è§„æ¨¡æ‹¥å µåœºæ™¯æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {report_file}")
        print("ğŸ“Š æ•°æ®åŒ…å«: 5x5ç½‘æ ¼ Ã— 4æ‹¥å µåœºæ™¯ Ã— å®Œæ•´ç®—æ³•å¯¹æ¯”")
        print("ğŸ¯ é‡ç‚¹éªŒè¯: è½¦è¾†æ‹¥å µåº¦ vs å¹³å‡åˆ°è¾¾æ—¶é—´")
        print("âœ… å®Œå…¨å¯ä»¥æ”¯æ’‘è®ºæ–‡çš„å®éªŒæ•°æ®éœ€æ±‚ï¼")
        print("=" * 60)

    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·ç¡®ä¿FastAPIæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")

if __name__ == "__main__":
    main()
